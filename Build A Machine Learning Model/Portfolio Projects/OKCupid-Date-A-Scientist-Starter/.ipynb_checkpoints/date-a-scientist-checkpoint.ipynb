{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Import the csv file into the project and preview the first few lines to get an idea of the dataset. As I plan to build multiple models using this dataset, the csv import will be placed in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "3                  socially awkward but i do my best  ...   \n",
       "4            i smile a lot and my inquisitive nature  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_csv():\n",
    "    return pd.read_csv('profiles.csv')\n",
    "df = import_csv()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
       "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
       "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
       "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   essay0       54458 non-null  object \n",
      " 7   essay1       52374 non-null  object \n",
      " 8   essay2       50308 non-null  object \n",
      " 9   essay3       48470 non-null  object \n",
      " 10  essay4       49409 non-null  object \n",
      " 11  essay5       49096 non-null  object \n",
      " 12  essay6       46175 non-null  object \n",
      " 13  essay7       47495 non-null  object \n",
      " 14  essay8       40721 non-null  object \n",
      " 15  essay9       47343 non-null  object \n",
      " 16  ethnicity    54266 non-null  object \n",
      " 17  height       59943 non-null  float64\n",
      " 18  income       59946 non-null  int64  \n",
      " 19  job          51748 non-null  object \n",
      " 20  last_online  59946 non-null  object \n",
      " 21  location     59946 non-null  object \n",
      " 22  offspring    24385 non-null  object \n",
      " 23  orientation  59946 non-null  object \n",
      " 24  pets         40025 non-null  object \n",
      " 25  religion     39720 non-null  object \n",
      " 26  sex          59946 non-null  object \n",
      " 27  sign         48890 non-null  object \n",
      " 28  smokes       54434 non-null  object \n",
      " 29  speaks       59896 non-null  object \n",
      " 30  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring in more detail\n",
    "\n",
    "Use `value_counts()` to explore the columns that appeal and identify potential features and targets for use in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_type\n",
       "average           14652\n",
       "fit               12711\n",
       "athletic          11819\n",
       "thin               4711\n",
       "curvy              3924\n",
       "a little extra     2629\n",
       "skinny             1777\n",
       "full figured       1009\n",
       "overweight          444\n",
       "jacked              421\n",
       "used up             355\n",
       "rather not say      198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "mostly anything        16585\n",
       "anything                6183\n",
       "strictly anything       5113\n",
       "mostly vegetarian       3444\n",
       "mostly other            1007\n",
       "strictly vegetarian      875\n",
       "vegetarian               667\n",
       "strictly other           452\n",
       "mostly vegan             338\n",
       "other                    331\n",
       "strictly vegan           228\n",
       "vegan                    136\n",
       "mostly kosher             86\n",
       "mostly halal              48\n",
       "strictly halal            18\n",
       "strictly kosher           18\n",
       "halal                     11\n",
       "kosher                    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drinks\n",
       "socially       41780\n",
       "rarely          5957\n",
       "often           5164\n",
       "not at all      3267\n",
       "very often       471\n",
       "desperately      322\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drinks'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugs\n",
       "never        37724\n",
       "sometimes     7732\n",
       "often          410\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "graduated from college/university    23959\n",
       "graduated from masters program        8961\n",
       "working on college/university         5712\n",
       "working on masters program            1683\n",
       "graduated from two-year college       1531\n",
       "graduated from high school            1428\n",
       "graduated from ph.d program           1272\n",
       "graduated from law school             1122\n",
       "working on two-year college           1074\n",
       "dropped out of college/university      995\n",
       "working on ph.d program                983\n",
       "college/university                     801\n",
       "graduated from space camp              657\n",
       "dropped out of space camp              523\n",
       "graduated from med school              446\n",
       "working on space camp                  445\n",
       "working on law school                  269\n",
       "two-year college                       222\n",
       "working on med school                  212\n",
       "dropped out of two-year college        191\n",
       "dropped out of masters program         140\n",
       "masters program                        136\n",
       "dropped out of ph.d program            127\n",
       "dropped out of high school             102\n",
       "high school                             96\n",
       "working on high school                  87\n",
       "space camp                              58\n",
       "ph.d program                            26\n",
       "law school                              19\n",
       "dropped out of law school               18\n",
       "dropped out of med school               12\n",
       "med school                              11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could be worth exploring results when using 'graduated from college/university' vs all other columns. This could be generalizing too much however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "white                                                                 32831\n",
       "asian                                                                  6134\n",
       "hispanic / latin                                                       2823\n",
       "black                                                                  2008\n",
       "other                                                                  1706\n",
       "                                                                      ...  \n",
       "middle eastern, indian, white                                             1\n",
       "asian, middle eastern, black, white, other                                1\n",
       "asian, middle eastern, indian, hispanic / latin, white, other             1\n",
       "black, native american, indian, pacific islander, hispanic / latin        1\n",
       "asian, black, indian                                                      1\n",
       "Name: count, Length: 217, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many values in the ethnicity column that only have 1 value. All the individual entries could be aggregated into the 'other' category, or, we could represent the data in binary using white and non-white as most entries identify as white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "san francisco, california         31064\n",
       "oakland, california                7214\n",
       "berkeley, california               4212\n",
       "san mateo, california              1331\n",
       "palo alto, california              1064\n",
       "                                  ...  \n",
       "south wellfleet, massachusetts        1\n",
       "orange, california                    1\n",
       "astoria, new york                     1\n",
       "london, united kingdom                1\n",
       "rochester, michigan                   1\n",
       "Name: count, Length: 199, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most users appear to be in San Francisco, California. Either drop the column or convert to San Francisco vs not San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "other                                7589\n",
       "student                              4882\n",
       "science / tech / engineering         4848\n",
       "computer / hardware / software       4709\n",
       "artistic / musical / writer          4439\n",
       "sales / marketing / biz dev          4391\n",
       "medicine / health                    3680\n",
       "education / academia                 3513\n",
       "executive / management               2373\n",
       "banking / financial / real estate    2266\n",
       "entertainment / media                2250\n",
       "law / legal services                 1381\n",
       "hospitality / travel                 1364\n",
       "construction / craftsmanship         1021\n",
       "clerical / administrative             805\n",
       "political / government                708\n",
       "rather not say                        436\n",
       "transportation                        366\n",
       "unemployed                            273\n",
       "retired                               250\n",
       "military                              204\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job could be a candidate for one-hot-encoding. There is a reasonable distribution within the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "-1          48442\n",
       " 20000       2952\n",
       " 100000      1621\n",
       " 80000       1111\n",
       " 30000       1048\n",
       " 40000       1005\n",
       " 50000        975\n",
       " 60000        736\n",
       " 70000        707\n",
       " 150000       631\n",
       " 1000000      521\n",
       " 250000       149\n",
       " 500000        48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most users did not answer this question so it should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring\n",
       "doesn&rsquo;t have kids                                7560\n",
       "doesn&rsquo;t have kids, but might want them           3875\n",
       "doesn&rsquo;t have kids, but wants them                3565\n",
       "doesn&rsquo;t want kids                                2927\n",
       "has kids                                               1883\n",
       "has a kid                                              1881\n",
       "doesn&rsquo;t have kids, and doesn&rsquo;t want any    1132\n",
       "has kids, but doesn&rsquo;t want more                   442\n",
       "has a kid, but doesn&rsquo;t want more                  275\n",
       "has a kid, and might want more                          231\n",
       "wants kids                                              225\n",
       "might want kids                                         182\n",
       "has kids, and might want more                           115\n",
       "has a kid, and wants more                                71\n",
       "has kids, and wants more                                 21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['offspring'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably a candidate to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orientation\n",
       "straight    51606\n",
       "gay          5573\n",
       "bisexual     2767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['orientation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use data to predict orientation. Could be done using binary and multiclass classification with a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pets\n",
       "likes dogs and likes cats          14814\n",
       "likes dogs                          7224\n",
       "likes dogs and has cats             4313\n",
       "has dogs                            4134\n",
       "has dogs and likes cats             2333\n",
       "likes dogs and dislikes cats        2029\n",
       "has dogs and has cats               1474\n",
       "has cats                            1406\n",
       "likes cats                          1063\n",
       "has dogs and dislikes cats           552\n",
       "dislikes dogs and likes cats         240\n",
       "dislikes dogs and dislikes cats      196\n",
       "dislikes cats                        122\n",
       "dislikes dogs and has cats            81\n",
       "dislikes dogs                         44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pets'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly another candidate for one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion\n",
       "agnosticism                                   2724\n",
       "other                                         2691\n",
       "agnosticism but not too serious about it      2636\n",
       "agnosticism and laughing about it             2496\n",
       "catholicism but not too serious about it      2318\n",
       "atheism                                       2175\n",
       "other and laughing about it                   2119\n",
       "atheism and laughing about it                 2074\n",
       "christianity                                  1957\n",
       "christianity but not too serious about it     1952\n",
       "other but not too serious about it            1554\n",
       "judaism but not too serious about it          1517\n",
       "atheism but not too serious about it          1318\n",
       "catholicism                                   1064\n",
       "christianity and somewhat serious about it     927\n",
       "atheism and somewhat serious about it          848\n",
       "other and somewhat serious about it            846\n",
       "catholicism and laughing about it              726\n",
       "judaism and laughing about it                  681\n",
       "buddhism but not too serious about it          650\n",
       "agnosticism and somewhat serious about it      642\n",
       "judaism                                        612\n",
       "christianity and very serious about it         578\n",
       "atheism and very serious about it              570\n",
       "catholicism and somewhat serious about it      548\n",
       "other and very serious about it                533\n",
       "buddhism and laughing about it                 466\n",
       "buddhism                                       403\n",
       "christianity and laughing about it             373\n",
       "buddhism and somewhat serious about it         359\n",
       "agnosticism and very serious about it          314\n",
       "judaism and somewhat serious about it          266\n",
       "hinduism but not too serious about it          227\n",
       "hinduism                                       107\n",
       "catholicism and very serious about it          102\n",
       "buddhism and very serious about it              70\n",
       "hinduism and somewhat serious about it          58\n",
       "islam                                           48\n",
       "hinduism and laughing about it                  44\n",
       "islam but not too serious about it              40\n",
       "judaism and very serious about it               22\n",
       "islam and somewhat serious about it             22\n",
       "islam and laughing about it                     16\n",
       "hinduism and very serious about it              14\n",
       "islam and very serious about it                 13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate to be dropped, too much variance in options. Could be aggragated into non-religious vs religious, or, split into individual religions regardless of seriousness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "m    35829\n",
       "f    24117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good candidate to be the target variable, relatively even split between the two options. Should be useful to model to make predictions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "gemini and it&rsquo;s fun to think about         1782\n",
       "scorpio and it&rsquo;s fun to think about        1772\n",
       "leo and it&rsquo;s fun to think about            1692\n",
       "libra and it&rsquo;s fun to think about          1649\n",
       "taurus and it&rsquo;s fun to think about         1640\n",
       "cancer and it&rsquo;s fun to think about         1597\n",
       "pisces and it&rsquo;s fun to think about         1592\n",
       "sagittarius and it&rsquo;s fun to think about    1583\n",
       "virgo and it&rsquo;s fun to think about          1574\n",
       "aries and it&rsquo;s fun to think about          1573\n",
       "aquarius and it&rsquo;s fun to think about       1503\n",
       "virgo but it doesn&rsquo;t matter                1497\n",
       "leo but it doesn&rsquo;t matter                  1457\n",
       "cancer but it doesn&rsquo;t matter               1454\n",
       "gemini but it doesn&rsquo;t matter               1453\n",
       "taurus but it doesn&rsquo;t matter               1450\n",
       "libra but it doesn&rsquo;t matter                1408\n",
       "aquarius but it doesn&rsquo;t matter             1408\n",
       "capricorn and it&rsquo;s fun to think about      1376\n",
       "sagittarius but it doesn&rsquo;t matter          1375\n",
       "aries but it doesn&rsquo;t matter                1373\n",
       "capricorn but it doesn&rsquo;t matter            1319\n",
       "pisces but it doesn&rsquo;t matter               1300\n",
       "scorpio but it doesn&rsquo;t matter              1264\n",
       "leo                                              1159\n",
       "libra                                            1098\n",
       "cancer                                           1092\n",
       "virgo                                            1029\n",
       "scorpio                                          1020\n",
       "gemini                                           1013\n",
       "taurus                                           1001\n",
       "aries                                             996\n",
       "pisces                                            992\n",
       "aquarius                                          954\n",
       "sagittarius                                       937\n",
       "capricorn                                         833\n",
       "scorpio and it matters a lot                       78\n",
       "leo and it matters a lot                           66\n",
       "cancer and it matters a lot                        63\n",
       "aquarius and it matters a lot                      63\n",
       "pisces and it matters a lot                        62\n",
       "gemini and it matters a lot                        62\n",
       "libra and it matters a lot                         52\n",
       "taurus and it matters a lot                        49\n",
       "aries and it matters a lot                         47\n",
       "sagittarius and it matters a lot                   47\n",
       "capricorn and it matters a lot                     45\n",
       "virgo and it matters a lot                         41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sign'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another candidate to group the data into individual signs and then one-hot-encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smokes\n",
       "no                43896\n",
       "sometimes          3787\n",
       "when drinking      3040\n",
       "yes                2231\n",
       "trying to quit     1480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be split into smokes and doesn't smoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaks\n",
       "english                                                                21828\n",
       "english (fluently)                                                      6628\n",
       "english (fluently), spanish (poorly)                                    2059\n",
       "english (fluently), spanish (okay)                                      1917\n",
       "english (fluently), spanish (fluently)                                  1288\n",
       "                                                                       ...  \n",
       "english (fluently), urdu (poorly), japanese (poorly), french (okay)        1\n",
       "english, spanish, hindi, c++                                               1\n",
       "english (fluently), japanese (okay), thai (okay), chinese (poorly)         1\n",
       "english (fluently), french (okay), italian (okay), hebrew (okay)           1\n",
       "english (fluently), french, farsi                                          1\n",
       "Name: count, Length: 7647, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be dropped as it might cause a data leak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "single            55697\n",
       "seeing someone     2064\n",
       "available          1865\n",
       "married             310\n",
       "unknown              10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should also be dropped as most people are in the single category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification Neural Network\n",
    "First, I plan to predict orientation using body_type, diet, drinks, drugs, ethnicity, job, pets, religion, sex, sign, and smokes. This will be done with a Neural Network and as orientation has 3 entries, it will be a multiclass model.\n",
    "\n",
    "## Plan of Action using Data Insights\n",
    "The data will need to be cleaned before I can build the model. The following will be done to each of my selected datapoints\n",
    "\n",
    "**The following will be normalized:**\n",
    "- diet\n",
    "- religion\n",
    "- sign\n",
    "\n",
    "*Note: specifically text normalization will be performed, this is done to remove variation in the data.*\n",
    "\n",
    "**The following will be one-hot-encoded:**\n",
    "- body_type\n",
    "- job\n",
    "- diet\n",
    "- religion\n",
    "- pets\n",
    "- sign\n",
    "\n",
    "**The following will be label encoded:**\n",
    "- orientation\n",
    "- drinks\n",
    "- drugs\n",
    "- ethnicity\n",
    "- sex\n",
    "- smokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NaN values\n",
    "\n",
    "Start by dropping any NaN values from our selected features. There are many spread through all the selected columns and this will make the future operations we are going to perform later easier (by not having to account for NaN). We will also remove all columns that we don't plan to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>job</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>transportation</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>white</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>student</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        body_type               diet    drinks      drugs  \\\n",
       "0  a little extra  strictly anything  socially      never   \n",
       "1         average       mostly other     often  sometimes   \n",
       "2            thin           anything  socially        NaN   \n",
       "3            thin         vegetarian  socially        NaN   \n",
       "4        athletic                NaN  socially      never   \n",
       "\n",
       "             ethnicity                          job  \\\n",
       "0         asian, white               transportation   \n",
       "1                white         hospitality / travel   \n",
       "2                  NaN                          NaN   \n",
       "3                white                      student   \n",
       "4  asian, black, other  artistic / musical / writer   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes orientation  \n",
       "0                              gemini  sometimes    straight  \n",
       "1                              cancer         no    straight  \n",
       "2  pisces but it doesn&rsquo;t matter         no    straight  \n",
       "3                              pisces         no    straight  \n",
       "4                            aquarius         no    straight  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = ['body_type', 'diet', 'drinks', 'drugs', 'ethnicity', 'job', 'pets', 'religion', 'sex', 'sign', 'smokes', 'orientation']\n",
    "\n",
    "df = df[selected_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59946, 12)\n",
      "(12426, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)  # lots of rows were lost, might be worth making some assumptions about na values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    "\n",
    "Reduce the number of possible inputs in diet, religion, and sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_diet = []\n",
    "for i in df['diet']:\n",
    "    if 'anything' in i:\n",
    "        new_diet.append('anything')\n",
    "    elif 'vegetarian' in i:\n",
    "        new_diet.append('vegetarian')\n",
    "    elif 'vegan' in i:\n",
    "        new_diet.append('vegan')\n",
    "    elif 'halal' in i:\n",
    "        new_diet.append('halal')\n",
    "    elif 'kosher' in i:\n",
    "        new_diet.append('kosher')\n",
    "    else:\n",
    "        new_diet.append('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the length of both the new list and the original column to check that the new column was made correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12426\n",
      "12426\n"
     ]
    }
   ],
   "source": [
    "print(len(new_diet))\n",
    "print(len(df['diet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_religion = []\n",
    "for i in df['religion']:\n",
    "    if 'agnosticism' in i:\n",
    "        new_religion.append('agnosticism')\n",
    "    elif 'catholicism' in i:\n",
    "        new_religion.append('catholicism')\n",
    "    elif 'atheism' in i:\n",
    "        new_religion.append('atheism')\n",
    "    elif 'christianity' in i:\n",
    "        new_religion.append('christianity')\n",
    "    elif 'judaism' in i:\n",
    "        new_religion.append('judaism')\n",
    "    elif 'buddhism' in i:\n",
    "        new_religion.append('buddhism')\n",
    "    elif 'hinduism' in i:\n",
    "        new_religion.append('hinduism')\n",
    "    elif 'islam' in i:\n",
    "        new_religion.append('islam')\n",
    "    else:\n",
    "        new_religion.append('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12426\n",
      "12426\n"
     ]
    }
   ],
   "source": [
    "print(len(df['religion']))\n",
    "print(len(new_religion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sign = []\n",
    "for i in df['sign']:\n",
    "    if 'aries' in i:\n",
    "        new_sign.append('aries')\n",
    "    elif 'aquarius' in i:\n",
    "        new_sign.append('aquarius')\n",
    "    elif 'cancer' in i:\n",
    "        new_sign.append('cancer')\n",
    "    elif 'capricorn' in i:\n",
    "        new_sign.append('capricorn')\n",
    "    elif 'gemini' in i:\n",
    "        new_sign.append('gemini')\n",
    "    elif 'leo' in i:\n",
    "        new_sign.append('leo')\n",
    "    elif 'libra' in i:\n",
    "        new_sign.append('libra')\n",
    "    elif 'pisces' in i:\n",
    "        new_sign.append('pisces')\n",
    "    elif 'sagittarius' in i:\n",
    "        new_sign.append('sagittarius')\n",
    "    elif 'scorpio' in i:\n",
    "        new_sign.append('scorpio')\n",
    "    elif 'taurus' in i:\n",
    "        new_sign.append('taurus')\n",
    "    else:\n",
    "        new_sign.append('virgo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12426\n",
      "12426\n"
     ]
    }
   ],
   "source": [
    "print(len(df['sign']))\n",
    "print(len(new_sign))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the old columns with the new lists we created, converting to a numpy array using `np.array` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>job</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a little extra</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>transportation</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>average</td>\n",
       "      <td>other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>white</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>christianity</td>\n",
       "      <td>f</td>\n",
       "      <td>sagittarius</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>athletic</td>\n",
       "      <td>anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>student</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>atheism</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>banking / financial / real estate</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>christianity</td>\n",
       "      <td>m</td>\n",
       "      <td>leo</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         body_type      diet      drinks      drugs     ethnicity  \\\n",
       "0   a little extra  anything    socially      never  asian, white   \n",
       "1          average     other       often  sometimes         white   \n",
       "7          average  anything    socially      never         white   \n",
       "9         athletic  anything  not at all      never         white   \n",
       "11         average  anything    socially      never         white   \n",
       "\n",
       "                                  job                       pets  \\\n",
       "0                      transportation  likes dogs and likes cats   \n",
       "1                hospitality / travel  likes dogs and likes cats   \n",
       "7         artistic / musical / writer  likes dogs and likes cats   \n",
       "9                             student  likes dogs and likes cats   \n",
       "11  banking / financial / real estate                 likes cats   \n",
       "\n",
       "        religion sex         sign     smokes orientation  \n",
       "0    agnosticism   m       gemini  sometimes    straight  \n",
       "1    agnosticism   m       cancer         no    straight  \n",
       "7   christianity   f  sagittarius         no    straight  \n",
       "9        atheism   m       cancer         no    straight  \n",
       "11  christianity   m          leo         no    straight  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet'] = np.array(new_diet)\n",
    "df['religion'] = np.array(new_religion)\n",
    "df['sign'] = np.array(new_sign)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding\n",
    "\n",
    "Now that we have reduced the number of possible inputs of certain columns, we can beging to clean our data using one-hot-encoding using pandas's `get_dummies`.\n",
    "\n",
    "Reminder that we are performing this operation on body_type, job, diet, religion, pets, and sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type_a little extra</th>\n",
       "      <th>body_type_athletic</th>\n",
       "      <th>body_type_average</th>\n",
       "      <th>body_type_curvy</th>\n",
       "      <th>...</th>\n",
       "      <th>sign_cancer</th>\n",
       "      <th>sign_capricorn</th>\n",
       "      <th>sign_gemini</th>\n",
       "      <th>sign_leo</th>\n",
       "      <th>sign_libra</th>\n",
       "      <th>sign_pisces</th>\n",
       "      <th>sign_sagittarius</th>\n",
       "      <th>sign_scorpio</th>\n",
       "      <th>sign_taurus</th>\n",
       "      <th>sign_virgo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>white</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        drinks      drugs     ethnicity sex     smokes orientation  \\\n",
       "0     socially      never  asian, white   m  sometimes    straight   \n",
       "1        often  sometimes         white   m         no    straight   \n",
       "7     socially      never         white   f         no    straight   \n",
       "9   not at all      never         white   m         no    straight   \n",
       "11    socially      never         white   m         no    straight   \n",
       "\n",
       "    body_type_a little extra  body_type_athletic  body_type_average  \\\n",
       "0                          1                   0                  0   \n",
       "1                          0                   0                  1   \n",
       "7                          0                   0                  1   \n",
       "9                          0                   1                  0   \n",
       "11                         0                   0                  1   \n",
       "\n",
       "    body_type_curvy  ...  sign_cancer  sign_capricorn  sign_gemini  sign_leo  \\\n",
       "0                 0  ...            0               0            1         0   \n",
       "1                 0  ...            1               0            0         0   \n",
       "7                 0  ...            0               0            0         0   \n",
       "9                 0  ...            1               0            0         0   \n",
       "11                0  ...            0               0            0         1   \n",
       "\n",
       "    sign_libra  sign_pisces  sign_sagittarius  sign_scorpio  sign_taurus  \\\n",
       "0            0            0                 0             0            0   \n",
       "1            0            0                 0             0            0   \n",
       "7            0            0                 1             0            0   \n",
       "9            0            0                 0             0            0   \n",
       "11           0            0                 0             0            0   \n",
       "\n",
       "    sign_virgo  \n",
       "0            0  \n",
       "1            0  \n",
       "7            0  \n",
       "9            0  \n",
       "11           0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_columns = ['body_type', 'job', 'diet', 'religion', 'pets', 'sign']\n",
    "\n",
    "df = pd.get_dummies(df, columns=one_hot_columns, dtype=int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Next is the label encoding. As a reminder we are label encoding the following columns: orientation, drinks, drugs, ethnicity, sex, smokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/hmp5l6cs7430g1fjc2lsw4x80000gn/T/ipykernel_66683/4113682078.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['orientation'] = df['orientation'].replace({'straight':0, 'gay':1, 'bisexual':2})\n",
      "/var/folders/2y/hmp5l6cs7430g1fjc2lsw4x80000gn/T/ipykernel_66683/4113682078.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sex'] = df['sex'].replace({'m':0, 'f':1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type_a little extra</th>\n",
       "      <th>body_type_athletic</th>\n",
       "      <th>body_type_average</th>\n",
       "      <th>body_type_curvy</th>\n",
       "      <th>...</th>\n",
       "      <th>sign_cancer</th>\n",
       "      <th>sign_capricorn</th>\n",
       "      <th>sign_gemini</th>\n",
       "      <th>sign_leo</th>\n",
       "      <th>sign_libra</th>\n",
       "      <th>sign_pisces</th>\n",
       "      <th>sign_sagittarius</th>\n",
       "      <th>sign_scorpio</th>\n",
       "      <th>sign_taurus</th>\n",
       "      <th>sign_virgo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    drinks  drugs  ethnicity  sex  smokes  orientation  \\\n",
       "0        1      0          1    0       1            0   \n",
       "1        1      1          0    0       0            0   \n",
       "7        1      0          0    1       0            0   \n",
       "9        0      0          0    0       0            0   \n",
       "11       1      0          0    0       0            0   \n",
       "\n",
       "    body_type_a little extra  body_type_athletic  body_type_average  \\\n",
       "0                          1                   0                  0   \n",
       "1                          0                   0                  1   \n",
       "7                          0                   0                  1   \n",
       "9                          0                   1                  0   \n",
       "11                         0                   0                  1   \n",
       "\n",
       "    body_type_curvy  ...  sign_cancer  sign_capricorn  sign_gemini  sign_leo  \\\n",
       "0                 0  ...            0               0            1         0   \n",
       "1                 0  ...            1               0            0         0   \n",
       "7                 0  ...            0               0            0         0   \n",
       "9                 0  ...            1               0            0         0   \n",
       "11                0  ...            0               0            0         1   \n",
       "\n",
       "    sign_libra  sign_pisces  sign_sagittarius  sign_scorpio  sign_taurus  \\\n",
       "0            0            0                 0             0            0   \n",
       "1            0            0                 0             0            0   \n",
       "7            0            0                 1             0            0   \n",
       "9            0            0                 0             0            0   \n",
       "11           0            0                 0             0            0   \n",
       "\n",
       "    sign_virgo  \n",
       "0            0  \n",
       "1            0  \n",
       "7            0  \n",
       "9            0  \n",
       "11           0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['orientation'] = df['orientation'].replace({'straight':0, 'gay':1, 'bisexual':2})\n",
    "df['sex'] = df['sex'].replace({'m':0, 'f':1})\n",
    "\n",
    "df['drinks'] = np.array([0 if i == 'not at all' else 1 for i in df['drinks']])\n",
    "df['drugs'] = np.array([0 if i == 'never' else 1 for i in df['drugs']])\n",
    "df['ethnicity'] = np.array([0 if i == 'white' else 1 for i in df['ethnicity']])\n",
    "df['smokes'] = np.array([0 if i == 'no' else 1 for i in df['smokes']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into features and classes\n",
    "\n",
    "Now that we have converted the categorical data into numerical, and cleaned it, we are ready to split our data and start creating the tensors which will be used to train and test the Neural Network.\n",
    "\n",
    "First we will need to import some more packages to do this. Those being `torch`, `torch.nn`, `torch.optim`, `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create the tensor containing the features and the tensor containing the classes to be split using `train_test_split`.\n",
    "We will create:\n",
    "- `X` - this tensor will contain all columns except for 'orientation' (classes column)\n",
    "- `y` - this tensor will only contain 'orientation' column\n",
    "\n",
    "So we know how many inputs our Neural Network will need, print the shape of our features tensor using `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12426, 80])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [i for i in df.columns if not i == 'orientation']\n",
    "\n",
    "X = torch.tensor(df[feature_columns].values, dtype=torch.float)\n",
    "y = torch.tensor(df['orientation'].values, dtype=torch.long)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has 12426 rows and 80 columns, so our model will have 80 nodes as input. We will use this information later when we create the Neural Network. For now we need to split our data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the Neural Network\n",
    "\n",
    "Now that we have our training and test sets we need to build a model that we can use them with. This model will have multiple hidden layers, so, we will use `nn.Sequential`. It will also use a combination of ReLU and Sigmoid functions and have a manual seed set to 42 (like our train_test_split) using `torch.manual_seed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(80, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model we can create our loss function and our optimizer. As we are creating a multiclass classifier, our loss function will be `CrossEntropyLoss` and our optimizer will be `Adam`. `CrossEntropyLoss` works well as it automatically will apply the softmax function to the output of our model and the Adam optimizer works well with multiclass classification too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our learning rate is quite small, this means that our model will adjust the weights in a relatively small way each epoch. To compensate for this we will train the model on 10,000 Epochs. Import `accuracy_score` from `sklearn` to keep track of our models performance every 100 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[100/10000], CELoss: 0.4282, Accuracy: 0.8626\n",
      "Epoch[200/10000], CELoss: 0.4017, Accuracy: 0.8642\n",
      "Epoch[300/10000], CELoss: 0.3830, Accuracy: 0.8730\n",
      "Epoch[400/10000], CELoss: 0.3539, Accuracy: 0.8881\n",
      "Epoch[500/10000], CELoss: 0.3464, Accuracy: 0.8909\n",
      "Epoch[600/10000], CELoss: 0.3414, Accuracy: 0.8925\n",
      "Epoch[700/10000], CELoss: 0.3375, Accuracy: 0.8933\n",
      "Epoch[800/10000], CELoss: 0.3358, Accuracy: 0.8938\n",
      "Epoch[900/10000], CELoss: 0.3326, Accuracy: 0.8949\n",
      "Epoch[1000/10000], CELoss: 0.3312, Accuracy: 0.8954\n",
      "Epoch[1100/10000], CELoss: 0.3290, Accuracy: 0.8963\n",
      "Epoch[1200/10000], CELoss: 0.3280, Accuracy: 0.8979\n",
      "Epoch[1300/10000], CELoss: 0.3268, Accuracy: 0.8980\n",
      "Epoch[1400/10000], CELoss: 0.3269, Accuracy: 0.8973\n",
      "Epoch[1500/10000], CELoss: 0.3242, Accuracy: 0.8983\n",
      "Epoch[1600/10000], CELoss: 0.3235, Accuracy: 0.8989\n",
      "Epoch[1700/10000], CELoss: 0.3223, Accuracy: 0.8989\n",
      "Epoch[1800/10000], CELoss: 0.3216, Accuracy: 0.8992\n",
      "Epoch[1900/10000], CELoss: 0.3208, Accuracy: 0.8996\n",
      "Epoch[2000/10000], CELoss: 0.3198, Accuracy: 0.9002\n",
      "Epoch[2100/10000], CELoss: 0.3200, Accuracy: 0.9002\n",
      "Epoch[2200/10000], CELoss: 0.3722, Accuracy: 0.8777\n",
      "Epoch[2300/10000], CELoss: 0.3367, Accuracy: 0.8936\n",
      "Epoch[2400/10000], CELoss: 0.3319, Accuracy: 0.8956\n",
      "Epoch[2500/10000], CELoss: 0.3284, Accuracy: 0.8972\n",
      "Epoch[2600/10000], CELoss: 0.3256, Accuracy: 0.8981\n",
      "Epoch[2700/10000], CELoss: 0.3238, Accuracy: 0.8990\n",
      "Epoch[2800/10000], CELoss: 0.3219, Accuracy: 0.8996\n",
      "Epoch[2900/10000], CELoss: 0.3205, Accuracy: 0.8997\n",
      "Epoch[3000/10000], CELoss: 0.3190, Accuracy: 0.9011\n",
      "Epoch[3100/10000], CELoss: 0.3179, Accuracy: 0.9012\n",
      "Epoch[3200/10000], CELoss: 0.3214, Accuracy: 0.9002\n",
      "Epoch[3300/10000], CELoss: 0.3152, Accuracy: 0.9027\n",
      "Epoch[3400/10000], CELoss: 0.3146, Accuracy: 0.9024\n",
      "Epoch[3500/10000], CELoss: 0.3138, Accuracy: 0.9028\n",
      "Epoch[3600/10000], CELoss: 0.3122, Accuracy: 0.9029\n",
      "Epoch[3700/10000], CELoss: 0.3200, Accuracy: 0.9011\n",
      "Epoch[3800/10000], CELoss: 0.3131, Accuracy: 0.9032\n",
      "Epoch[3900/10000], CELoss: 0.3115, Accuracy: 0.9031\n",
      "Epoch[4000/10000], CELoss: 0.3123, Accuracy: 0.9036\n",
      "Epoch[4100/10000], CELoss: 0.3109, Accuracy: 0.9033\n",
      "Epoch[4200/10000], CELoss: 0.3105, Accuracy: 0.9035\n",
      "Epoch[4300/10000], CELoss: 0.3110, Accuracy: 0.9030\n",
      "Epoch[4400/10000], CELoss: 0.3080, Accuracy: 0.9045\n",
      "Epoch[4500/10000], CELoss: 0.3076, Accuracy: 0.9045\n",
      "Epoch[4600/10000], CELoss: 0.3088, Accuracy: 0.9039\n",
      "Epoch[4700/10000], CELoss: 0.3069, Accuracy: 0.9048\n",
      "Epoch[4800/10000], CELoss: 0.3063, Accuracy: 0.9044\n",
      "Epoch[4900/10000], CELoss: 0.3061, Accuracy: 0.9048\n",
      "Epoch[5000/10000], CELoss: 0.3060, Accuracy: 0.9049\n",
      "Epoch[5100/10000], CELoss: 0.3062, Accuracy: 0.9048\n",
      "Epoch[5200/10000], CELoss: 0.3064, Accuracy: 0.9041\n",
      "Epoch[5300/10000], CELoss: 0.3058, Accuracy: 0.9042\n",
      "Epoch[5400/10000], CELoss: 0.3044, Accuracy: 0.9048\n",
      "Epoch[5500/10000], CELoss: 0.3057, Accuracy: 0.9043\n",
      "Epoch[5600/10000], CELoss: 0.3064, Accuracy: 0.9035\n",
      "Epoch[5700/10000], CELoss: 0.3061, Accuracy: 0.9043\n",
      "Epoch[5800/10000], CELoss: 0.3038, Accuracy: 0.9041\n",
      "Epoch[5900/10000], CELoss: 0.3050, Accuracy: 0.9042\n",
      "Epoch[6000/10000], CELoss: 0.3036, Accuracy: 0.9043\n",
      "Epoch[6100/10000], CELoss: 0.3044, Accuracy: 0.9038\n",
      "Epoch[6200/10000], CELoss: 0.3032, Accuracy: 0.9045\n",
      "Epoch[6300/10000], CELoss: 0.3032, Accuracy: 0.9048\n",
      "Epoch[6400/10000], CELoss: 0.3025, Accuracy: 0.9050\n",
      "Epoch[6500/10000], CELoss: 0.3046, Accuracy: 0.9040\n",
      "Epoch[6600/10000], CELoss: 0.3035, Accuracy: 0.9036\n",
      "Epoch[6700/10000], CELoss: 0.3083, Accuracy: 0.9033\n",
      "Epoch[6800/10000], CELoss: 0.3061, Accuracy: 0.9025\n",
      "Epoch[6900/10000], CELoss: 0.3062, Accuracy: 0.9025\n",
      "Epoch[7000/10000], CELoss: 0.3025, Accuracy: 0.9048\n",
      "Epoch[7100/10000], CELoss: 0.3019, Accuracy: 0.9047\n",
      "Epoch[7200/10000], CELoss: 0.3024, Accuracy: 0.9043\n",
      "Epoch[7300/10000], CELoss: 0.3073, Accuracy: 0.9018\n",
      "Epoch[7400/10000], CELoss: 0.3088, Accuracy: 0.9024\n",
      "Epoch[7500/10000], CELoss: 0.3074, Accuracy: 0.9030\n",
      "Epoch[7600/10000], CELoss: 0.3058, Accuracy: 0.9020\n",
      "Epoch[7700/10000], CELoss: 0.3052, Accuracy: 0.9025\n",
      "Epoch[7800/10000], CELoss: 0.3046, Accuracy: 0.9022\n",
      "Epoch[7900/10000], CELoss: 0.3054, Accuracy: 0.9020\n",
      "Epoch[8000/10000], CELoss: 0.3069, Accuracy: 0.9030\n",
      "Epoch[8100/10000], CELoss: 0.3043, Accuracy: 0.9026\n",
      "Epoch[8200/10000], CELoss: 0.3046, Accuracy: 0.9027\n",
      "Epoch[8300/10000], CELoss: 0.3056, Accuracy: 0.9021\n",
      "Epoch[8400/10000], CELoss: 0.3032, Accuracy: 0.9036\n",
      "Epoch[8500/10000], CELoss: 0.3046, Accuracy: 0.9018\n",
      "Epoch[8600/10000], CELoss: 0.3027, Accuracy: 0.9027\n",
      "Epoch[8700/10000], CELoss: 0.3034, Accuracy: 0.9023\n",
      "Epoch[8800/10000], CELoss: 0.3030, Accuracy: 0.9025\n",
      "Epoch[8900/10000], CELoss: 0.3026, Accuracy: 0.9025\n",
      "Epoch[9000/10000], CELoss: 0.3037, Accuracy: 0.9019\n",
      "Epoch[9100/10000], CELoss: 0.3118, Accuracy: 0.9030\n",
      "Epoch[9200/10000], CELoss: 0.3043, Accuracy: 0.9012\n",
      "Epoch[9300/10000], CELoss: 0.3039, Accuracy: 0.9008\n",
      "Epoch[9400/10000], CELoss: 0.3079, Accuracy: 0.8994\n",
      "Epoch[9500/10000], CELoss: 0.3040, Accuracy: 0.9010\n",
      "Epoch[9600/10000], CELoss: 0.3047, Accuracy: 0.9011\n",
      "Epoch[9700/10000], CELoss: 0.3024, Accuracy: 0.9011\n",
      "Epoch[9800/10000], CELoss: 0.3037, Accuracy: 0.9009\n",
      "Epoch[9900/10000], CELoss: 0.3029, Accuracy: 0.9011\n",
      "Epoch[10000/10000], CELoss: 0.6184, Accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_epochs = 10000\n",
    "for i in range(num_epochs):\n",
    "    predictions = model(X_train)\n",
    "    CELoss = loss(predictions, y_train)\n",
    "    CELoss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        predicted_labels = torch.argmax(predictions, dim=1)\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        print(f'Epoch[{(i+1)}/{num_epochs}], CELoss: {CELoss.item():.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Now that we have trained our model it is time to evaluate it. We need to switch the model into evaluation mode and use our test set to determine its effectiveness at predicting orientation. Import `classification_report` from `sklearn` for a detailed understanding of our models performance. Print both the accuracy score of the model and the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8423169750603379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92      2175\n",
      "           1       0.16      0.03      0.05       181\n",
      "           2       0.18      0.14      0.16       130\n",
      "\n",
      "    accuracy                           0.84      2486\n",
      "   macro avg       0.41      0.37      0.38      2486\n",
      "weighted avg       0.79      0.84      0.81      2486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test)\n",
    "    test_labels = torch.argmax(test_predictions, dim=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, test_labels)\n",
    "report = classification_report(y_test, test_labels)\n",
    "\n",
    "print(accuracy)\n",
    "print(report)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model appears to do pretty well, that is until we remember that most entries identified as 'straight'... We have built a very naive model, by predicting 0 in most cases it was very accurate but it could not identify 'gay' or 'bisexual' as demonstrated by the abysmal precision, recall, and f1-scores. This was the case before we performed the `dropna` function so lets look at the distribution now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orientation\n",
       "0    10749\n",
       "1     1015\n",
       "2      662\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['orientation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the math we can see that those that identify as 'straight' make up **86.5%** of our data, with 'gay' at **8.2%** and 'bisexual' at **5.3%**. We have overfit our model, it is technically performing worse than if it simply predicted 0 for all values. The evidence of overfitting can be seen in the output of our training epochs where the model got 'stuck' around **85-90%** accuracy. To improve this model, we should consider randomly sampling ~1000 rows of those who identify as 'straight'. This could allow the model to identify the nuances of the different classes in the feature set rather than one class being overwhelmingly in the majority; allowing for more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lessons learned from the multiclass neural network, we will use a DataFrame containing fewer features and a more evenly distributed target column. First, we need to set the DateFrame to its original state using the method we delcared earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to think about feature selection, as we are creating a binary model, we can only have two possible values in our column we are trying to predict. The column 'sex' will be our `y`. \n",
    "\n",
    "We will try to predict 'sex' using the following columns in our `X`: 'jobs', 'drinks', 'drugs', and 'smokes'. We will need to perform similar changes as we did before to clean our data. Those being:\n",
    "\n",
    "**One-Hot-Encoded:**\n",
    "- job\n",
    "\n",
    "**Label Encoded:**\n",
    "- drinks\n",
    "- drugs\n",
    "- smokes\n",
    "- sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>smokes</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transportation</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>student</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>no</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job    drinks      drugs     smokes sex\n",
       "0               transportation  socially      never  sometimes   m\n",
       "1         hospitality / travel     often  sometimes         no   m\n",
       "2                          NaN  socially        NaN         no   m\n",
       "3                      student  socially        NaN         no   m\n",
       "4  artistic / musical / writer  socially      never         no   m"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_cols = ['job', 'drinks', 'drugs', 'smokes', 'sex']\n",
    "\n",
    "df = df[selected_cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "First, we will drop any missing values from our selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59946, 5)\n",
      "(37987, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see that there are far more columns in this DataFrame than the one that we used for the multiclass Neural Network. However, this doesn't mean that our dataset is immune to saturation. It is possible that all ~12000 missing values belongs to those who either put male or female in their profiles. Lets check this using `value_counts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "m    22690\n",
       "f    15297\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most users already identified as male before we dropped rows with missing values. This distribution is less extreme than that of the 'orientation' column so can continue to encoding the data.\n",
    "\n",
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/hmp5l6cs7430g1fjc2lsw4x80000gn/T/ipykernel_66683/3027707200.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sex'] = df['sex'].replace({'m':0, 'f':1})\n"
     ]
    }
   ],
   "source": [
    "df['sex'] = df['sex'].replace({'m':0, 'f':1})\n",
    "df['drinks'] = np.array([0 if i == 'not at all' else 1 for i in df['drinks']])\n",
    "df['drugs'] = np.array([0 if i == 'never' else 1 for i in df['drugs']])\n",
    "df['smokes'] = np.array([0 if i == 'no' else 1 for i in df['smokes']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>smokes</th>\n",
       "      <th>sex</th>\n",
       "      <th>job_artistic / musical / writer</th>\n",
       "      <th>job_banking / financial / real estate</th>\n",
       "      <th>job_clerical / administrative</th>\n",
       "      <th>job_computer / hardware / software</th>\n",
       "      <th>job_construction / craftsmanship</th>\n",
       "      <th>job_education / academia</th>\n",
       "      <th>...</th>\n",
       "      <th>job_military</th>\n",
       "      <th>job_other</th>\n",
       "      <th>job_political / government</th>\n",
       "      <th>job_rather not say</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_sales / marketing / biz dev</th>\n",
       "      <th>job_science / tech / engineering</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_transportation</th>\n",
       "      <th>job_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   drinks  drugs  smokes  sex  job_artistic / musical / writer  \\\n",
       "0       1      0       1    0                                0   \n",
       "1       1      1       0    0                                0   \n",
       "4       1      0       0    0                                1   \n",
       "7       1      0       0    1                                1   \n",
       "9       0      0       0    0                                0   \n",
       "\n",
       "   job_banking / financial / real estate  job_clerical / administrative  \\\n",
       "0                                      0                              0   \n",
       "1                                      0                              0   \n",
       "4                                      0                              0   \n",
       "7                                      0                              0   \n",
       "9                                      0                              0   \n",
       "\n",
       "   job_computer / hardware / software  job_construction / craftsmanship  \\\n",
       "0                                   0                                 0   \n",
       "1                                   0                                 0   \n",
       "4                                   0                                 0   \n",
       "7                                   0                                 0   \n",
       "9                                   0                                 0   \n",
       "\n",
       "   job_education / academia  ...  job_military  job_other  \\\n",
       "0                         0  ...             0          0   \n",
       "1                         0  ...             0          0   \n",
       "4                         0  ...             0          0   \n",
       "7                         0  ...             0          0   \n",
       "9                         0  ...             0          0   \n",
       "\n",
       "   job_political / government  job_rather not say  job_retired  \\\n",
       "0                           0                   0            0   \n",
       "1                           0                   0            0   \n",
       "4                           0                   0            0   \n",
       "7                           0                   0            0   \n",
       "9                           0                   0            0   \n",
       "\n",
       "   job_sales / marketing / biz dev  job_science / tech / engineering  \\\n",
       "0                                0                                 0   \n",
       "1                                0                                 0   \n",
       "4                                0                                 0   \n",
       "7                                0                                 0   \n",
       "9                                0                                 0   \n",
       "\n",
       "   job_student  job_transportation  job_unemployed  \n",
       "0            0                   1               0  \n",
       "1            0                   0               0  \n",
       "4            0                   0               0  \n",
       "7            0                   0               0  \n",
       "9            1                   0               0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['job'], dtype=int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Now that we have our final DataFrame, we can begin training our Neural Network. We will split our data in features and classes, then further split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30389, 24])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [i for i in df.columns if not i == 'sex']\n",
    "\n",
    "X = torch.tensor(df[feature_cols].values, dtype=torch.float)\n",
    "y = torch.tensor(df['sex'].values, dtype=torch.float).view(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will need to have 24 input nodes (as shown by the result of `.shape`) and as this is a binary classification model, it will have an output of 1 with the sigmoid function applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(24, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model using 10000 epochs again, however, this time we will use a binary cross entropy loss function `BCELoss()` and stochastic gradient descent `SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1000/10000], BCELoss: 0.6743, Accuracy: 0.5962\n",
      "Epoch[2000/10000], BCELoss: 0.6738, Accuracy: 0.5962\n",
      "Epoch[3000/10000], BCELoss: 0.6733, Accuracy: 0.5962\n",
      "Epoch[4000/10000], BCELoss: 0.6726, Accuracy: 0.5962\n",
      "Epoch[5000/10000], BCELoss: 0.6715, Accuracy: 0.5962\n",
      "Epoch[6000/10000], BCELoss: 0.6697, Accuracy: 0.5962\n",
      "Epoch[7000/10000], BCELoss: 0.6664, Accuracy: 0.5962\n",
      "Epoch[8000/10000], BCELoss: 0.6603, Accuracy: 0.5962\n",
      "Epoch[9000/10000], BCELoss: 0.6502, Accuracy: 0.5962\n",
      "Epoch[10000/10000], BCELoss: 0.6387, Accuracy: 0.6308\n"
     ]
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 10000\n",
    "for i in range(num_epochs):\n",
    "    predictions = model(X_train)\n",
    "    BCELoss = loss(predictions, y_train)\n",
    "    BCELoss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        predicted_labels = (predictions >=.5).int()\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        print(f'Epoch[{(i+1)}/{num_epochs}], BCELoss: {BCELoss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model made no gains in its accuracy, this points to a too restrictive learning rate. We will repeat the process but this time with a learning rate of 0.07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1000/10000], BCELoss: 0.6193, Accuracy: 0.6414\n",
      "Epoch[2000/10000], BCELoss: 0.6183, Accuracy: 0.6418\n",
      "Epoch[3000/10000], BCELoss: 0.6179, Accuracy: 0.6418\n",
      "Epoch[4000/10000], BCELoss: 0.6176, Accuracy: 0.6419\n",
      "Epoch[5000/10000], BCELoss: 0.6175, Accuracy: 0.6423\n",
      "Epoch[6000/10000], BCELoss: 0.6174, Accuracy: 0.6423\n",
      "Epoch[7000/10000], BCELoss: 0.6172, Accuracy: 0.6426\n",
      "Epoch[8000/10000], BCELoss: 0.6171, Accuracy: 0.6427\n",
      "Epoch[9000/10000], BCELoss: 0.6171, Accuracy: 0.6427\n",
      "Epoch[10000/10000], BCELoss: 0.6170, Accuracy: 0.6430\n"
     ]
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "num_epochs = 10000\n",
    "for i in range(num_epochs):\n",
    "    predictions = model(X_train)\n",
    "    BCELoss = loss(predictions, y_train)\n",
    "    BCELoss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        predicted_labels = (predictions >=.5).int()\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        print(f'Epoch[{(i+1)}/{num_epochs}], BCELoss: {BCELoss.item():.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6379310344827587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.78      0.72      4572\n",
      "         1.0       0.56      0.43      0.48      3026\n",
      "\n",
      "    accuracy                           0.64      7598\n",
      "   macro avg       0.62      0.60      0.60      7598\n",
      "weighted avg       0.63      0.64      0.63      7598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test)\n",
    "    test_labels = (test_predictions >= .5).int()\n",
    "print(accuracy_score(y_test, test_labels))\n",
    "print(classification_report(y_test, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Our Neural Network models have not done too well so far...fortunately we can use clustering to predict whether a user is male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
